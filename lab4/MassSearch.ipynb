{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "d_A-lEBi8scn",
        "wIifMRwUDJom"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anteii/HPC-Labs/blob/main/lab4/MassSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Notebook setup"
      ],
      "metadata": {
        "id": "d_A-lEBi8scn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h3ADkaa98p9v"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyMy41kP9E4n",
        "outputId": "d6b26204-fbd2-47a3-a13c-2b2ab39e7571"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsUOFd5r9F5Z",
        "outputId": "56a4b5c7-cde8-4005-edf8-97c5924b562a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 18 16:27:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples.git\n",
        "!make -C /content/cuda-samples/Samples/1_Utilities/deviceQueryDrv/\n",
        "!/content/cuda-samples/bin/x86_64/linux/release/deviceQueryDrv"
      ],
      "metadata": {
        "id": "Qefp13KK9I94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90fdac8-a720-4cf7-a065-2d69e3fdd71e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuda-samples'...\n",
            "remote: Enumerating objects: 11024, done.\u001b[K\n",
            "remote: Counting objects: 100% (11024/11024), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1850/1850), done.\u001b[K\n",
            "remote: Total 11024 (delta 9174), reused 10979 (delta 9148), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (11024/11024), 127.02 MiB | 16.72 MiB/s, done.\n",
            "Resolving deltas: 100% (9174/9174), done.\n",
            "Checking out files: 100% (3615/3615), done.\n",
            "make: Entering directory '/content/cuda-samples/Samples/1_Utilities/deviceQueryDrv'\n",
            "/usr/local/cuda/bin/nvcc -ccbin g++ -I../../../Common  -m64    --threads 0 --std=c++11 -gencode arch=compute_35,code=compute_35 -o deviceQueryDrv.o -c deviceQueryDrv.cpp\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "/usr/local/cuda/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_35,code=compute_35 -o deviceQueryDrv deviceQueryDrv.o  -L/usr/local/cuda/lib64/stubs -lcuda\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "mkdir -p ../../../bin/x86_64/linux/release\n",
            "cp deviceQueryDrv ../../../bin/x86_64/linux/release\n",
            "make: Leaving directory '/content/cuda-samples/Samples/1_Utilities/deviceQueryDrv'\n",
            "/content/cuda-samples/bin/x86_64/linux/release/deviceQueryDrv Starting...\n",
            "\n",
            "CUDA Device Query (Driver API) statically linked version \n",
            "Detected 1 CUDA Capable device(s)\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version:                           11.2\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 15110 MBytes (15843721216 bytes)\n",
            "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
            "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Max Texture Dimension Sizes                    1D=(131072) 2D=(131072, 65536) 3D=(16384, 16384, 16384)\n",
            "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
            "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of threads per block:           1024\n",
            "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
            "  Max dimension size of a grid size (x,y,z):    (2147483647, 65535, 65535)\n",
            "  Texture alignment:                             512 bytes\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
            "  Run time limit on kernels:                     No\n",
            "  Integrated GPU sharing Host Memory:            No\n",
            "  Support host page-locked memory mapping:       Yes\n",
            "  Concurrent kernel execution:                   Yes\n",
            "  Alignment requirement for Surfaces:            Yes\n",
            "  Device has ECC support:                        Enabled\n",
            "  Device supports Unified Addressing (UVA):      Yes\n",
            "  Device supports Managed Memory:                Yes\n",
            "  Device supports Compute Preemption:            Yes\n",
            "  Supports Cooperative Kernel Launch:            Yes\n",
            "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
            "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
            "  Compute Mode:\n",
            "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
            "Result = PASS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir src"
      ],
      "metadata": {
        "id": "W9LyRtqyDR44"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python (CPU)"
      ],
      "metadata": {
        "id": "wIifMRwUDJom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(41)\n",
        "\n",
        "def generate_sub(alphabet, h_min, h_max):\n",
        "  sub_len = np.random.randint(h_min, h_max, size=1)\n",
        "  return np.random.choice(alphabet, size=sub_len)\n",
        "\n",
        "def gen_d(alphabet, subs):\n",
        "  d = {ch: [] for ch in alphabet}\n",
        "  for sub_ind, sub in enumerate(subs):\n",
        "    for ch_ind, ch in enumerate(sub):\n",
        "      d[ch].append((sub_ind, ch_ind))\n",
        "  return d\n",
        "\n",
        "def gen_working_mat(subs, N, H):\n",
        "  mat = np.array([len(sub) for sub in subs])\n",
        "  return mat.reshape(-1,1).repeat(H, axis=1)\n",
        "\n",
        "def iterate(text, d, mat):\n",
        "  for ind, ch in enumerate(text):\n",
        "    for pair in d[ch]:\n",
        "      mat[pair[0], ind - pair[1]] -= 1\n",
        "  return mat\n",
        "\n",
        "def is_contain(mat):\n",
        "  return (mat == 0).any(axis=1)\n",
        "\n",
        "def find_indices(mat):\n",
        "  sub_ind, pos_ind = np.where(mat == 0)\n",
        "  return np.stack([sub_ind, pos_ind]).T"
      ],
      "metadata": {
        "id": "fyH29wm9iV8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define alphabet\n",
        "S = 6\n",
        "alphabet = np.arange(0, S, dtype=np.uint8)\n",
        "# Example\n",
        "#S = 6\n",
        "#alphabet = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]"
      ],
      "metadata": {
        "id": "sNq5HlmTiZNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define text\n",
        "H = 100\n",
        "text = np.random.choice(alphabet, size=H)\n",
        "\n",
        "# Example\n",
        "#H = 6\n",
        "#text = np.array([\"a\", \"a\", \"e\", \"f\", \"e\", \"d\"])"
      ],
      "metadata": {
        "id": "CmDOIUtOieoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_min, h_max = 1, 20\n",
        "N = 10\n",
        "subs = [generate_sub(alphabet, h_min, h_max) for i in range(N)]\n",
        "\n",
        "# Example\n",
        "#N = 3\n",
        "#subs = [np.array([\"a\", \"a\"]), np.array([\"a\"]), np.array([\"f\", \"e\", \"d\"])]"
      ],
      "metadata": {
        "id": "4IVzcTOQitKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = gen_d(alphabet, subs)\n",
        "mat = gen_working_mat(subs, N, H)"
      ],
      "metadata": {
        "id": "0i4OZhnWjiBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mat = iterate(text, d, mat)"
      ],
      "metadata": {
        "id": "qxk3a2TIHq5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_contain(mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R41OB_3yJjPB",
        "outputId": "b7ccd0a8-8d0e-4cef-b34f-1abfc24b2cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False,  True, False, False, False,\n",
              "       False])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_indices(mat)"
      ],
      "metadata": {
        "id": "DkKADroWkrJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78da73c-318c-41a9-8318-d1860809b5f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5,  8],\n",
              "       [ 5, 10],\n",
              "       [ 5, 18],\n",
              "       [ 5, 27],\n",
              "       [ 5, 32],\n",
              "       [ 5, 34],\n",
              "       [ 5, 35],\n",
              "       [ 5, 47],\n",
              "       [ 5, 49],\n",
              "       [ 5, 50],\n",
              "       [ 5, 53],\n",
              "       [ 5, 56],\n",
              "       [ 5, 57],\n",
              "       [ 5, 66],\n",
              "       [ 5, 67],\n",
              "       [ 5, 71],\n",
              "       [ 5, 76],\n",
              "       [ 5, 77],\n",
              "       [ 5, 79],\n",
              "       [ 5, 80],\n",
              "       [ 5, 82],\n",
              "       [ 5, 85],\n",
              "       [ 5, 86],\n",
              "       [ 5, 95]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C++ (CUDA)"
      ],
      "metadata": {
        "id": "UGHTg-QpnK5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/gpu.cu\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <map>\n",
        "#include <fstream>\n",
        "#include <string>\n",
        "#include <chrono>\n",
        "\n",
        "using namespace std;\n",
        "using namespace std::chrono;\n",
        "\n",
        "enum SearchType{\n",
        "  Indicies,\n",
        "  Entries\n",
        "};\n",
        "\n",
        "enum Device{\n",
        "  CPU,\n",
        "  GPU\n",
        "};\n",
        "\n",
        "ostream& operator<<(ostream& os, const vector<pair<int, int>>& pairs){\n",
        "    os << \"{\";\n",
        "    for (int i = 0; i < pairs.size(); ++i){\n",
        "      auto it = pairs[i];\n",
        "      os << \"(\" << it.first << \", \" << it.second;\n",
        "      os << (i == pairs.size() - 1 ? \")}\" : \"), \");\n",
        "    }\n",
        "\n",
        "    return os;\n",
        "}\n",
        "\n",
        "ostream& operator<<(ostream& os, const vector<bool>& flags){\n",
        "    os << \"{\";\n",
        "    for (int i = 0; i < flags.size(); ++i){\n",
        "      os << (flags[i] ? \"True\" : \"False\");\n",
        "      os << (i == flags.size() - 1 ? \"}\" : \", \");\n",
        "    }\n",
        "\n",
        "    return os;\n",
        "}\n",
        "\n",
        "template<typename T>\n",
        "void printText(const vector<T>& text, ostream& os){ \n",
        "   for (int i = 0; i < text.size(); ++i)\n",
        "   {\n",
        "     os << (T)text[i] << (i == text.size() - 1 ? \"\" : \" \");\n",
        "   }\n",
        "   os << endl;\n",
        "}\n",
        "\n",
        "template<typename T>\n",
        "void printSubs(const vector<vector<T>>& subs, ostream& os){ \n",
        "   for(auto sub : subs){\n",
        "     printText(sub, os);\n",
        "   }\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "vector<int> getSubSizes(const vector<vector<T>>& subs){\n",
        "  vector<int> subsSizes(subs.size(), 0);\n",
        "  for (int subInd = 0; subInd < subs.size(); ++subInd){\n",
        "    subsSizes[subInd] = subs[subInd].size();\n",
        "  }\n",
        "  return subsSizes;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "map<T, vector<pair<int, int>>> generateDict(const vector<T>& alphabet, const vector<vector<T>>& subs){\n",
        "  map<T, vector<pair<int, int>>> dict;\n",
        "  for (auto chr : alphabet){\n",
        "    dict[chr] = vector<pair<int, int>>();\n",
        "  }\n",
        "  \n",
        "  for (int sub_ind = 0; sub_ind < subs.size(); ++sub_ind){\n",
        "    auto sub = subs[sub_ind];\n",
        "    for (int chr_ind = 0; chr_ind < sub.size(); ++chr_ind){\n",
        "      auto chr = sub[chr_ind];\n",
        "      dict[chr].push_back({sub_ind, chr_ind});\n",
        "    }\n",
        "  }\n",
        "  \n",
        "  return dict;\n",
        "}\n",
        "\n",
        "vector<vector<int>> generateMatrix(const vector<int>& subsSizes, int textSize){\n",
        "  vector<vector<int>> mat;\n",
        "  for (auto subSize : subsSizes){\n",
        "    mat.push_back(vector<int>(textSize, subSize));\n",
        "  }\n",
        "  return mat;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "vector<T> generateText(const vector<T>& alphabet, int size){\n",
        "  vector<T> text(size);\n",
        "  for (int i = 0; i < size; ++i){\n",
        "      int ind = rand() % alphabet.size();\n",
        "      text[i] = alphabet[ind];\n",
        "  }\n",
        "  return text;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "vector<vector<T>> generateSubs(const vector<T>& alphabet, int n, int sizeMin, int sizeMax){\n",
        "  vector<vector<T>> subs;\n",
        "\n",
        "  for (int subInd = 0; subInd < n; ++subInd){\n",
        "    int size = sizeMin + rand() % (sizeMax - sizeMin + 1); \n",
        "    auto sub = generateText(alphabet, size);\n",
        "    subs.push_back(sub);\n",
        "  }\n",
        "\n",
        "  return subs;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "float iterateCPU(const vector<T>& text, const map<T, vector<pair<int, int>>>& dict,\n",
        "            vector<vector<int>>& matrix){\n",
        "  auto start = high_resolution_clock::now();\n",
        "  \n",
        "  for (int chr_ind = 0; chr_ind < text.size(); ++chr_ind){\n",
        "    for (const auto pair : dict.at(text[chr_ind])){\n",
        "      if (chr_ind - pair.second > -1){\n",
        "        //printf(\"%d\\t%d\\n\", pair.first, chr_ind - pair.second);\n",
        "        matrix[pair.first][chr_ind - pair.second]--;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  auto end = high_resolution_clock::now();\n",
        "  auto duration = duration_cast<microseconds>(end - start);\n",
        "  auto totalTime = duration.count() / 1000.0f;\n",
        "\n",
        "  return totalTime;\n",
        "}\n",
        "\n",
        "void checkError(cudaError_t error){\n",
        "\tif (error != cudaSuccess){\n",
        "\t\tcout << \"Error\" << endl;\n",
        "\t\tcerr << cudaGetErrorString(error) << endl;\n",
        "    exit(1);\n",
        "\t}\n",
        "}\n",
        "\n",
        "// H - length of a text\n",
        "// N - number of substrings\n",
        "// C - Alphabet size\n",
        "template<int blockSize>\n",
        "__global__ void kernel(int* text, int H, int* matrix, int N, int* dict, int C) {\n",
        "  int tid = threadIdx.x;\n",
        "  int i = blockIdx.x * blockSize + tid;\n",
        "\n",
        "  if (i >= H) return;\n",
        "\n",
        "  int chr = text[i];\n",
        "\n",
        "  int offset = 3 * chr;\n",
        "  int pos = dict[offset + 1];\n",
        "  int n = dict[offset + 2];\n",
        "\n",
        "  //if (i == 0){\n",
        "  // printf(\"GPU steps\\n\");\n",
        "  //}\n",
        "  \n",
        "\n",
        "  for (int pair_ind = 0; pair_ind < n; ++pair_ind){\n",
        "    int ind = pos + pair_ind * 2;\n",
        "    if (i - dict[ind + 1] > -1){\n",
        "      //printf(\"%d\\t%d\\n\", dict[ind], i - dict[ind + 1]);\n",
        "      atomicSub(matrix + dict[ind] * H + i - dict[ind + 1], 1);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "// working if char type is int and alphabet is 0..N\n",
        "float iterateGPU(const vector<int>& text, const map<int, vector<pair<int, int>>>& dict,\n",
        "            vector<vector<int>>& matrix){\n",
        "  \n",
        "  int textSize = text.size();\n",
        "  int N = matrix.size();\n",
        "  int H = matrix[0].size();\n",
        "  int alphabetSize = dict.size();\n",
        "  int entryNumber = 0;\n",
        "  float totalTime = 0;\n",
        "\n",
        "  // Flatten map [(char, offset, n)][(sub_ind, pos_ind)]\n",
        "  vector<int> dictHost;\n",
        "\n",
        "  // Temporary memory for flat pairs\n",
        "  int* flatPairs = new int[2 * entryNumber];\n",
        "\n",
        "  int curPos = 0;\n",
        "  for (auto const& it : dict){\n",
        "    dictHost.push_back(it.first);\n",
        "    dictHost.push_back(3 * alphabetSize + entryNumber * 2);\n",
        "    dictHost.push_back(it.second.size());\n",
        "\n",
        "    entryNumber += it.second.size();\n",
        "\n",
        "    // Copy map data to a device [(sub_ind, pos_ind)]\n",
        "    for (auto pair : it.second){\n",
        "      flatPairs[curPos++] = pair.first;\n",
        "      flatPairs[curPos++] = pair.second;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  int dictDeviceSize = 3 * alphabetSize + 2 * entryNumber;\n",
        "  \n",
        "  // Device pointers\n",
        "  int* textDevice;\n",
        "  int* matrixDevice;\n",
        "  int* dictDevice; // [(char, offset, n)][(sub_ind, pos_ind)]\n",
        "\n",
        "  // Copy text to a device\n",
        "  checkError(cudaMalloc(&textDevice, textSize * sizeof(int)));\n",
        "  checkError(cudaMemcpy(textDevice, &text[0], textSize * sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  // Flatten and copy matrix to a device\n",
        "  checkError(cudaMalloc(&matrixDevice, N * H * sizeof(int)));\n",
        "  for (int sub_ind = 0; sub_ind < N; ++sub_ind){\n",
        "    checkError(cudaMemcpy(matrixDevice + sub_ind * H, &matrix[sub_ind][0], textSize * sizeof(int), cudaMemcpyHostToDevice));\n",
        "  }\n",
        "\n",
        "  // Copy meta part of map to a device [(char, offset, n)]\n",
        "  checkError(cudaMalloc(&dictDevice, dictDeviceSize * sizeof(int)));\n",
        "  checkError(cudaMemcpy(dictDevice, &dictHost[0], 3 * alphabetSize * sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  checkError(cudaMemcpy(dictDevice + 3 * alphabetSize, flatPairs, 2 * entryNumber * sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  const int blockX = 512;\n",
        "  const int gridX = int(1.0f * (textSize - 1) / blockX) + 1;\n",
        "\n",
        "  cudaEvent_t startEvent, stopEvent;\n",
        "  checkError(cudaEventCreate(&startEvent));\n",
        "  checkError(cudaEventCreate(&stopEvent));\n",
        "  \n",
        "  checkError(cudaEventRecord(startEvent, 0));\n",
        "\n",
        "  kernel<blockX><<<gridX, blockX>>>(textDevice, textSize, matrixDevice, N, dictDevice, alphabetSize);\n",
        "\n",
        "  checkError(cudaEventRecord(stopEvent, 0));\n",
        "\n",
        "  checkError(cudaDeviceSynchronize());\n",
        "  checkError(cudaEventElapsedTime(&totalTime, startEvent, stopEvent));\n",
        "\n",
        "  for (int i = 0; i < N; ++i){\n",
        "    checkError(cudaMemcpy(&matrix[i][0], (matrixDevice + i * H), H * sizeof(int), cudaMemcpyDeviceToHost));\n",
        "  }\n",
        "\n",
        "  delete[] flatPairs;\n",
        "  cudaFree(matrixDevice);\n",
        "  cudaFree(textDevice);\n",
        "  cudaFree(dictDevice);\n",
        "\n",
        "  return totalTime;\n",
        "}\n",
        "\n",
        "vector<pair<int, int>> findIndices(const vector<vector<int>>& mat){\n",
        "  vector<pair<int, int>> result;\n",
        "\n",
        "  int textSize = mat[0].size();\n",
        "\n",
        "  for (int subInd = 0; subInd < mat.size(); ++subInd){\n",
        "    for (int textPos = 0; textPos < textSize; ++textPos){\n",
        "      if (mat[subInd][textPos] == 0){\n",
        "        result.push_back({subInd, textPos});\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  return result;\n",
        "}\n",
        "\n",
        "vector<bool> findEntries(const vector<vector<int>>& mat){\n",
        "  \n",
        "  vector<bool> result(mat.size(), false);\n",
        "  int textSize = mat[0].size();\n",
        "\n",
        "  for (int subInd = 0; subInd < mat.size(); ++subInd){\n",
        "    for (int textPos = 0; textPos < textSize; ++textPos){\n",
        "      if (mat[subInd][textPos] == 0){\n",
        "        result[subInd] = true;\n",
        "        break;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  return result;\n",
        "}\n",
        "\n",
        "bool checkEquality(const vector<vector<int>>& mat1, const vector<vector<int>>& mat2){\n",
        "  for (int i = 0; i < mat1.size(); ++i){\n",
        "    for (int j = 0; j < mat1[0].size(); ++j){\n",
        "      if (mat1[i][j] != mat2[i][j]){\n",
        "        return false;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  return true;\n",
        "}\n",
        "\n",
        "int cumDiv(const vector<vector<int>>& mat1, const vector<vector<int>>& mat2){\n",
        "  int c = 0;\n",
        "  for (int i = 0; i < mat1.size(); ++i){\n",
        "    for (int j = 0; j < mat1[0].size(); ++j){\n",
        "      if (mat1[i][j] != mat2[i][j]){\n",
        "        c++;\n",
        "        //printf(\"i=%d j=%d\\n\", i, j);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  return c;\n",
        "}\n",
        "\n",
        "void experiment(int textSize, int subN, int subSizeMin, \n",
        "            int subSizeMax, SearchType searchType){\n",
        "  ofstream myfile;\n",
        "  myfile.open (\"data.txt\");\n",
        "\n",
        "  float totalTime = 0.0f;\n",
        "\n",
        "  // Generate 8bit alphabet\n",
        "\n",
        "  int alphabetSize = 256;\n",
        "  vector<int> alphabet(alphabetSize);\n",
        "  for (int i = 0; i < alphabetSize; ++i){\n",
        "    alphabet[i] = i;\n",
        "  }\n",
        "\n",
        "  // Generate text\n",
        "  vector<int> text = generateText<int>(alphabet, textSize);\n",
        "  // Generate substrings\n",
        "  auto subs = generateSubs<int>(alphabet, subN, subSizeMin, subSizeMax);\n",
        "  vector<int> subsSizes = getSubSizes<int>(subs);\n",
        "  \n",
        "  // Preliminary step\n",
        "  map<int, vector<pair<int, int>>> dict = generateDict<int>(alphabet, subs);\n",
        "  vector<vector<int>> mat1 = generateMatrix(subsSizes, textSize);\n",
        "  vector<vector<int>> mat2 = generateMatrix(subsSizes, textSize); // copy\n",
        "\n",
        "  // Save input data\n",
        "  myfile << textSize << \" \" << subN << \" \" <<  subSizeMin << \" \"\n",
        "     << subSizeMax << \" \" << searchType << endl;\n",
        "  printText(alphabet, myfile);\n",
        "  printText(text, myfile);\n",
        "  printSubs(subs, myfile);\n",
        "\n",
        "  printText<int>(text, cout);\n",
        "\n",
        "  printf(\"Original matrix\\n\");\n",
        "  for (int i = 0; i < mat1.size(); ++i){\n",
        "    for (int j = 0; j < mat1[0].size(); ++j){\n",
        "      cout << mat1[i][j] << \"\\t\";\n",
        "    }\n",
        "    cout << endl;\n",
        "  }\n",
        "\n",
        "  // CPU\n",
        "  totalTime = iterateCPU<int>(text, dict, mat1);\n",
        "  cout << \"CPU time: \" << totalTime << \"ms\" << endl;\n",
        "  \n",
        "  // CUDA\n",
        "  totalTime = iterateGPU(text, dict, mat2);\n",
        "  cout << \"GPU time: \" << totalTime << endl;\n",
        "\n",
        "  // Check equality\n",
        "  if (checkEquality(mat1, mat2)){\n",
        "    cout << \"Correct!\" << endl;\n",
        "  }\n",
        "  else{\n",
        "    cout << \"Incorect! \" << cumDiv(mat1, mat2) << \" errors\" << endl;\n",
        "  }\n",
        "\n",
        "  printf(\"CPU final matrix\\n\");\n",
        "  for (int i = 0; i < mat1.size(); ++i){\n",
        "    for (int j = 0; j < mat1[0].size(); ++j){\n",
        "      cout << mat1[i][j] << \"\\t\";\n",
        "    }\n",
        "    cout << endl;\n",
        "  }\n",
        "  cout << endl << endl;\n",
        "  printf(\"GPU final matrix\\n\");\n",
        "  for (int i = 0; i < mat1.size(); ++i){\n",
        "    for (int j = 0; j < mat1[0].size(); ++j){\n",
        "      cout << mat2[i][j] << \"\\t\";\n",
        "    }\n",
        "    cout << endl;\n",
        "  }\n",
        "  \n",
        "\n",
        "  // Interpret results\n",
        "  switch(searchType){\n",
        "    case Indicies:{\n",
        "      vector<pair<int, int>> indices = findIndices(mat1);\n",
        "      myfile << indices << endl;\n",
        "    }\n",
        "    break;\n",
        "    case Entries:{\n",
        "      vector<bool> entries = findEntries(mat1);\n",
        "      myfile << entries << endl;\n",
        "      break;\n",
        "    } \n",
        "  }\n",
        "  myfile.close();\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "  srand(42);\n",
        "\n",
        "  // For some reason doesn't work if don't make cuda call in main/experiment functions\n",
        "  int* a;\n",
        "  cudaMalloc(&a, 1 * sizeof(int));\n",
        "  cudaFree(a);\n",
        "\n",
        "  // Parse command line arguments\n",
        "  int textSize = stoi(argv[1]);\n",
        "  int subN = stoi(argv[2]);\n",
        "  int subSizeMin = stoi(argv[3]);\n",
        "  int subSizeMax = stoi(argv[4]);\n",
        "  SearchType searchType = (SearchType)stoi(argv[5]);\n",
        "\n",
        "  // Run experiment\n",
        "  experiment(textSize, subN, subSizeMin, subSizeMax, searchType);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRlaDv9i3kQ_",
        "outputId": "34f2e273-eaf3-4b6e-d470-08231bca6835"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc src/gpu.cu -o gpu"
      ],
      "metadata": {
        "id": "5bKZn9LA3zla"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   textSize subN subSizeMin subSizeMax searchType(0 - inds, 1 - entry) device (0 - CPU, 1 - GPU)\n",
        "!./gpu 100 10 1 10 0 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZi2RTuN35--",
        "outputId": "2bd77422-8109-458c-8934-ba0d90b3f542"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70 100 49 41 100 134 237 156 215 31 194 7 37 72 32 162 196 168 90 235 11 32 65 73 79 139 241 248 205 48 241 19 148 34 60 248 168 41 149 128 73 87 135 110 159 167 17 99 80 107 78 91 140 143 164 219 27 149 211 232 197 197 251 90 231 55 82 144 96 231 16 169 62 151 24 221 62 41 65 142 148 143 233 32 31 141 251 58 34 207 34 232 148 29 66 123 84 148 11 180\n",
            "Original matrix\n",
            "5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t\n",
            "6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t\n",
            "7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t\n",
            "9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t\n",
            "10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t\n",
            "9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t\n",
            "10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t\n",
            "10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t\n",
            "CPU time: 0.037ms\n",
            "1\n",
            "2\n",
            "GPU time: 0.022784\n",
            "Correct!\n",
            "CPU final matrix\n",
            "5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t4\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t\n",
            "6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t\n",
            "7\t7\t7\t7\t7\t7\t7\t6\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t6\t7\t7\t7\t\n",
            "9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t\n",
            "10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t9\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t\n",
            "9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t\n",
            "10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t\n",
            "10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t\n",
            "\n",
            "\n",
            "GPU final matrix\n",
            "5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t4\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t\n",
            "6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t\n",
            "7\t7\t7\t7\t7\t7\t7\t6\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t6\t7\t7\t7\t\n",
            "9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t\n",
            "10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t9\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t\n",
            "9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t8\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t\n",
            "10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t\n",
            "10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t9\t10\t10\t9\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cpu = \"\"\"14 -6\n",
        "13 -1\n",
        "4 7\n",
        "6 6\n",
        "10 9\n",
        "5 11\n",
        "12 10\n",
        "19 14\n",
        "14 10\n",
        "14 19\n",
        "20 11\n",
        "12 17\n",
        "2 16\n",
        "7 21\n",
        "10 19\n",
        "1 26\n",
        "6 18\n",
        "5 24\n",
        "13 22\n",
        "9 20\n",
        "6 25\n",
        "1 30\n",
        "6 22\n",
        "8 29\n",
        "14 28\n",
        "17 31\n",
        "5 32\n",
        "13 30\n",
        "2 36\n",
        "9 45\n",
        "20 41\n",
        "15 47\n",
        "13 54\n",
        "0 56\n",
        "18 52\n",
        "8 59\n",
        "14 55\n",
        "5 56\n",
        "7 65\n",
        "5 61\n",
        "9 66\n",
        "15 71\n",
        "18 71\n",
        "5 74\n",
        "18 75\n",
        "17 79\n",
        "9 82\n",
        "12 79\n",
        "10 84\n",
        "8 91\n",
        "17 91\n",
        "10 89\n",
        "15 90\n",
        "17 91\n",
        "9 85\n",
        "2 91\n",
        "4 96\n",
        "17 96\"\"\"\n",
        "gpu = \"\"\"2\t91\n",
        "17\t96\n",
        "17\t31\n",
        "5\t32\n",
        "2\t36\n",
        "9\t45\n",
        "15\t47\n",
        "13\t54\n",
        "0\t56\n",
        "8\t59\n",
        "14\t55\n",
        "5\t56\n",
        "7\t65\n",
        "5\t61\n",
        "9\t66\n",
        "18\t71\n",
        "5\t74\n",
        "18\t75\n",
        "17\t79\n",
        "9\t82\n",
        "12\t79\n",
        "10\t84\n",
        "8\t91\n",
        "17\t91\n",
        "10\t89\n",
        "9\t85\n",
        "14\t-6\n",
        "13\t-1\n",
        "4\t7\n",
        "10\t9\n",
        "5\t11\n",
        "12\t10\n",
        "19\t14\n",
        "14\t10\n",
        "14\t19\n",
        "12\t17\n",
        "2\t16\n",
        "7\t21\n",
        "1\t26\n",
        "5\t24\n",
        "9\t20\n",
        "6\t25\n",
        "1\t30\n",
        "8\t29\n",
        "4\t96\n",
        "13\t30\n",
        "20\t41\n",
        "18\t52\n",
        "6\t6\n",
        "20\t11\n",
        "10\t19\n",
        "6\t18\n",
        "13\t22\n",
        "6\t22\n",
        "14\t28\n",
        "15\t71\n",
        "15\t90\n",
        "17\t91\"\"\"\n",
        "\n",
        "cpu = [list(map(int, it.split())) for it in cpu.split(\"\\n\")]\n",
        "gpu = [list(map(int, it.split())) for it in gpu.split(\"\\n\")]\n",
        "sorted(cpu, key=lambda x: x[0])\n",
        "\n",
        "\n",
        "exceptions = []\n",
        "\n",
        "for itc in cpu:\n",
        "  flag = True\n",
        "  for itg in gpu:\n",
        "    if itc[0] == itg[0] and itc[1] == itg[1]:\n",
        "      flag = False\n",
        "      break\n",
        "  if flag:\n",
        "    exceptions.append(itc)\n",
        "exceptions"
      ],
      "metadata": {
        "id": "sqWV0F1Q37Nc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fbffca8-e2b7-4b76-e3d3-bda52086cd82"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QFq1_rbXC0B9"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}