{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wIifMRwUDJom",
        "yQEL0yA7moCW"
      ],
      "authorship_tag": "ABX9TyNMnUepKb/eU1gxWein6qN/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anteii/HPC-Labs/blob/main/lab4/MassSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Notebook setup"
      ],
      "metadata": {
        "id": "d_A-lEBi8scn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h3ADkaa98p9v"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyMy41kP9E4n",
        "outputId": "d9363a6b-3df7-4eb6-d129-ea04b4c896d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsUOFd5r9F5Z",
        "outputId": "b877916d-cf95-4005-fc49-166dcb121d04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 17 21:06:26 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples.git\n",
        "!make -C /content/cuda-samples/Samples/1_Utilities/deviceQueryDrv/\n",
        "!/content/cuda-samples/bin/x86_64/linux/release/deviceQueryDrv"
      ],
      "metadata": {
        "id": "Qefp13KK9I94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ee9c217-55e2-4628-96b9-04853d09440c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuda-samples'...\n",
            "remote: Enumerating objects: 11024, done.\u001b[K\n",
            "remote: Counting objects: 100% (11024/11024), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1850/1850), done.\u001b[K\n",
            "remote: Total 11024 (delta 9174), reused 10979 (delta 9148), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (11024/11024), 127.02 MiB | 16.36 MiB/s, done.\n",
            "Resolving deltas: 100% (9174/9174), done.\n",
            "Checking out files: 100% (3615/3615), done.\n",
            "make: Entering directory '/content/cuda-samples/Samples/1_Utilities/deviceQueryDrv'\n",
            "/usr/local/cuda/bin/nvcc -ccbin g++ -I../../../Common  -m64    --threads 0 --std=c++11 -gencode arch=compute_35,code=compute_35 -o deviceQueryDrv.o -c deviceQueryDrv.cpp\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "/usr/local/cuda/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_35,code=compute_35 -o deviceQueryDrv deviceQueryDrv.o  -L/usr/local/cuda/lib64/stubs -lcuda\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "mkdir -p ../../../bin/x86_64/linux/release\n",
            "cp deviceQueryDrv ../../../bin/x86_64/linux/release\n",
            "make: Leaving directory '/content/cuda-samples/Samples/1_Utilities/deviceQueryDrv'\n",
            "/content/cuda-samples/bin/x86_64/linux/release/deviceQueryDrv Starting...\n",
            "\n",
            "CUDA Device Query (Driver API) statically linked version \n",
            "Detected 1 CUDA Capable device(s)\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version:                           11.2\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 15110 MBytes (15843721216 bytes)\n",
            "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
            "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Max Texture Dimension Sizes                    1D=(131072) 2D=(131072, 65536) 3D=(16384, 16384, 16384)\n",
            "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
            "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of threads per block:           1024\n",
            "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
            "  Max dimension size of a grid size (x,y,z):    (2147483647, 65535, 65535)\n",
            "  Texture alignment:                             512 bytes\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
            "  Run time limit on kernels:                     No\n",
            "  Integrated GPU sharing Host Memory:            No\n",
            "  Support host page-locked memory mapping:       Yes\n",
            "  Concurrent kernel execution:                   Yes\n",
            "  Alignment requirement for Surfaces:            Yes\n",
            "  Device has ECC support:                        Enabled\n",
            "  Device supports Unified Addressing (UVA):      Yes\n",
            "  Device supports Managed Memory:                Yes\n",
            "  Device supports Compute Preemption:            Yes\n",
            "  Supports Cooperative Kernel Launch:            Yes\n",
            "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
            "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
            "  Compute Mode:\n",
            "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
            "Result = PASS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir src"
      ],
      "metadata": {
        "id": "W9LyRtqyDR44"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python (CPU)"
      ],
      "metadata": {
        "id": "wIifMRwUDJom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(41)\n",
        "\n",
        "def generate_sub(alphabet, h_min, h_max):\n",
        "  sub_len = np.random.randint(h_min, h_max, size=1)\n",
        "  return np.random.choice(alphabet, size=sub_len)\n",
        "\n",
        "def gen_d(alphabet, subs):\n",
        "  d = {ch: [] for ch in alphabet}\n",
        "  for sub_ind, sub in enumerate(subs):\n",
        "    for ch_ind, ch in enumerate(sub):\n",
        "      d[ch].append((sub_ind, ch_ind))\n",
        "  return d\n",
        "\n",
        "def gen_working_mat(subs, N, H):\n",
        "  mat = np.array([len(sub) for sub in subs])\n",
        "  return mat.reshape(-1,1).repeat(H, axis=1)\n",
        "\n",
        "def iterate(text, d, mat):\n",
        "  for ind, ch in enumerate(text):\n",
        "    for pair in d[ch]:\n",
        "      mat[pair[0], ind - pair[1]] -= 1\n",
        "  return mat\n",
        "\n",
        "def is_contain(mat):\n",
        "  return (mat == 0).any(axis=1)\n",
        "\n",
        "def find_indices(mat):\n",
        "  sub_ind, pos_ind = np.where(mat == 0)\n",
        "  return np.stack([sub_ind, pos_ind]).T"
      ],
      "metadata": {
        "id": "fyH29wm9iV8V"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define alphabet\n",
        "S = 6\n",
        "alphabet = np.arange(0, S, dtype=np.uint8)\n",
        "# Example\n",
        "#S = 6\n",
        "#alphabet = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]"
      ],
      "metadata": {
        "id": "sNq5HlmTiZNd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define text\n",
        "H = 100\n",
        "text = np.random.choice(alphabet, size=H)\n",
        "\n",
        "# Example\n",
        "#H = 6\n",
        "#text = np.array([\"a\", \"a\", \"e\", \"f\", \"e\", \"d\"])"
      ],
      "metadata": {
        "id": "CmDOIUtOieoX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_min, h_max = 1, 20\n",
        "N = 10\n",
        "subs = [generate_sub(alphabet, h_min, h_max) for i in range(N)]\n",
        "\n",
        "# Example\n",
        "#N = 3\n",
        "#subs = [np.array([\"a\", \"a\"]), np.array([\"a\"]), np.array([\"f\", \"e\", \"d\"])]"
      ],
      "metadata": {
        "id": "4IVzcTOQitKX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = gen_d(alphabet, subs)\n",
        "mat = gen_working_mat(subs, N, H)"
      ],
      "metadata": {
        "id": "0i4OZhnWjiBb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mat = iterate(text, d, mat)"
      ],
      "metadata": {
        "id": "qxk3a2TIHq5S"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_contain(mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R41OB_3yJjPB",
        "outputId": "ef65d765-d597-4500-b5e5-c7d7700bffd2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False,  True, False, False, False,\n",
              "       False])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_indices(mat)"
      ],
      "metadata": {
        "id": "DkKADroWkrJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea57e81-3b3b-47c0-8df8-f18de832eaae"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5,  8],\n",
              "       [ 5, 10],\n",
              "       [ 5, 18],\n",
              "       [ 5, 27],\n",
              "       [ 5, 32],\n",
              "       [ 5, 34],\n",
              "       [ 5, 35],\n",
              "       [ 5, 47],\n",
              "       [ 5, 49],\n",
              "       [ 5, 50],\n",
              "       [ 5, 53],\n",
              "       [ 5, 56],\n",
              "       [ 5, 57],\n",
              "       [ 5, 66],\n",
              "       [ 5, 67],\n",
              "       [ 5, 71],\n",
              "       [ 5, 76],\n",
              "       [ 5, 77],\n",
              "       [ 5, 79],\n",
              "       [ 5, 80],\n",
              "       [ 5, 82],\n",
              "       [ 5, 85],\n",
              "       [ 5, 86],\n",
              "       [ 5, 95]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C++"
      ],
      "metadata": {
        "id": "yQEL0yA7moCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/cpu.cpp\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <map>\n",
        "#include <fstream>\n",
        "#include <string>\n",
        "#include <chrono>\n",
        "\n",
        "using namespace std;\n",
        "using namespace std::chrono;\n",
        "\n",
        "enum SearchType{\n",
        "  Indicies,\n",
        "  Entries\n",
        "};\n",
        "\n",
        "template <typename T>\n",
        "vector<int> getSubSizes(const vector<vector<T>>& subs){\n",
        "  vector<int> subsSizes(subs.size(), 0);\n",
        "  for (int subInd = 0; subInd < subs.size(); ++subInd){\n",
        "    subsSizes[subInd] = subs[subInd].size();\n",
        "  }\n",
        "  return subsSizes;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "map<T, vector<pair<int, int>>> generateDict(const vector<T>& alphabet, const vector<vector<T>>& subs){\n",
        "  map<T, vector<pair<int, int>>> dict;\n",
        "  for (auto chr : alphabet){\n",
        "    dict[chr] = vector<pair<int, int>>();\n",
        "  }\n",
        "  \n",
        "  for (int sub_ind = 0; sub_ind < subs.size(); ++sub_ind){\n",
        "    auto sub = subs[sub_ind];\n",
        "    for (int chr_ind = 0; chr_ind < sub.size(); ++chr_ind){\n",
        "      auto chr = sub[chr_ind];\n",
        "      dict[chr].push_back({sub_ind, chr_ind});\n",
        "    }\n",
        "  }\n",
        "  \n",
        "  return dict;\n",
        "}\n",
        "\n",
        "vector<vector<int>> generateMatrix(const vector<int>& subsSizes, int textSize){\n",
        "  vector<vector<int>> mat;\n",
        "  for (auto subSize : subsSizes){\n",
        "    mat.push_back(vector<int>(textSize, subSize));\n",
        "  }\n",
        "  return mat;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "vector<T> generateText(const vector<T>& alphabet, int size){\n",
        "  vector<T> text(size);\n",
        "  for (int i = 0; i < size; ++i){\n",
        "      int ind = rand() % alphabet.size();\n",
        "      text[i] = alphabet[ind];\n",
        "  }\n",
        "  return text;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "vector<vector<T>> generateSubs(const vector<T>& alphabet, int n, int sizeMin, int sizeMax){\n",
        "  vector<vector<T>> subs;\n",
        "\n",
        "  for (int subInd = 0; subInd < n; ++subInd){\n",
        "    int size = sizeMin + rand() % (sizeMax - sizeMin + 1); \n",
        "    auto sub = generateText(alphabet, size);\n",
        "    subs.push_back(sub);\n",
        "  }\n",
        "\n",
        "  return subs;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "void iterate(const vector<T>& text, const map<T, vector<pair<int, int>>>& dict,\n",
        "            vector<vector<int>>& matrix){\n",
        "  for (int chr_ind = 0; chr_ind < text.size(); ++chr_ind){\n",
        "    for (const auto pair : dict.at(text[chr_ind])){\n",
        "      matrix[pair.first][chr_ind - pair.second]--;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "vector<pair<int, int>> findIndices(const vector<vector<int>>& mat){\n",
        "  vector<pair<int, int>> result;\n",
        "\n",
        "  int textSize = mat[0].size();\n",
        "\n",
        "  for (int subInd = 0; subInd < mat.size(); ++subInd){\n",
        "    for (int textPos = 0; textPos < textSize; ++textPos){\n",
        "      if (mat[subInd][textPos] == 0){\n",
        "        result.push_back({subInd, textPos});\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  return result;\n",
        "}\n",
        "\n",
        "vector<bool> findEntries(const vector<vector<int>>& mat){\n",
        "  \n",
        "  vector<bool> result(mat.size(), false);\n",
        "  int textSize = mat[0].size();\n",
        "\n",
        "  for (int subInd = 0; subInd < mat.size(); ++subInd){\n",
        "    for (int textPos = 0; textPos < textSize; ++textPos){\n",
        "      if (mat[subInd][textPos] == 0){\n",
        "        result[subInd] = true;\n",
        "        break;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  return result;\n",
        "}\n",
        "\n",
        "ostream& operator<<(ostream& os, const vector<pair<int, int>>& pairs){\n",
        "    os << \"{\";\n",
        "    for (int i = 0; i < pairs.size(); ++i){\n",
        "      auto it = pairs[i];\n",
        "      os << \"(\" << it.first << \", \" << it.second;\n",
        "      os << (i == pairs.size() - 1 ? \")}\" : \"), \");\n",
        "    }\n",
        "\n",
        "    return os;\n",
        "}\n",
        "\n",
        "ostream& operator<<(ostream& os, const vector<bool>& flags){\n",
        "    os << \"{\";\n",
        "    for (int i = 0; i < flags.size(); ++i){\n",
        "      os << (flags[i] ? \"True\" : \"False\");\n",
        "      os << (i == flags.size() - 1 ? \"}\" : \", \");\n",
        "    }\n",
        "\n",
        "    return os;\n",
        "}\n",
        "\n",
        "template<typename T>\n",
        "void printText(const vector<T>& text, ostream& os){ \n",
        "   for (int i = 0; i < text.size(); ++i)\n",
        "   {\n",
        "     os << (T)text[i] << (i == text.size() - 1 ? \"\" : \" \");\n",
        "   }\n",
        "   os << endl;\n",
        "}\n",
        "\n",
        "template<typename T>\n",
        "void printSubs(const vector<vector<T>>& subs, ostream& os){ \n",
        "   for(auto sub : subs){\n",
        "     printText(sub, os);\n",
        "   }\n",
        "}\n",
        "\n",
        "void search(int textSize, int subN, int subSizeMin, int subSizeMax, SearchType searchType){\n",
        "  \n",
        "  ofstream myfile;\n",
        "  myfile.open (\"data.txt\");\n",
        "\n",
        "  // Generate 8bit alphabet\n",
        "  int alphabetSize = 256;\n",
        "  vector<int> alphabet(alphabetSize);\n",
        "  for (int i = 0; i < alphabetSize; ++i){\n",
        "    alphabet[i] = i;\n",
        "  }\n",
        "\n",
        "  // Generate text\n",
        "  vector<int> text = generateText<int>(alphabet, textSize);\n",
        "\n",
        "  // Generate substrings\n",
        "  auto subs = generateSubs<int>(alphabet, subN, subSizeMin, subSizeMax);\n",
        "  vector<int> subsSizes = getSubSizes<int>(subs);\n",
        "\n",
        "  // Preliminary step\n",
        "  map<int, vector<pair<int, int>>> dict = generateDict<int>(alphabet, subs);\n",
        "  vector<vector<int>> mat = generateMatrix(subsSizes, textSize);\n",
        "  \n",
        "  // Algorithm steps\n",
        "  iterate<int>(text, dict, mat);\n",
        "\n",
        "  // Save input data\n",
        "  myfile << textSize << \" \" << subN << \" \" <<  subSizeMin << \" \"\n",
        "     << subSizeMax << \" \" << searchType << endl;\n",
        "  printText(alphabet, myfile);\n",
        "  printText(text, myfile);\n",
        "  printSubs(subs, myfile);\n",
        "\n",
        "  // Interpret results\n",
        "  switch(searchType){\n",
        "    case Indicies:{\n",
        "      vector<pair<int, int>> indices = findIndices(mat);\n",
        "      myfile << indices << endl;\n",
        "    }\n",
        "    break;\n",
        "    case Entries:{\n",
        "      vector<bool> entries = findEntries(mat);\n",
        "      myfile << entries << endl;\n",
        "      break;\n",
        "    } \n",
        "  }\n",
        "  myfile.close();\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "  srand(42);\n",
        "\n",
        "  int textSize = stoi(argv[1]);\n",
        "  int subN = stoi(argv[2]);\n",
        "  int subSizeMin = stoi(argv[3]);\n",
        "  int subSizeMax = stoi(argv[4]);\n",
        "  SearchType searchType = (SearchType)stoi(argv[5]);\n",
        "\n",
        "  auto start = high_resolution_clock::now();\n",
        "\n",
        "  search(textSize, subN, subSizeMin, subSizeMax, searchType);\n",
        "\n",
        "  auto end = high_resolution_clock::now();\n",
        "\n",
        "  auto duration = duration_cast<microseconds>(end - start);\n",
        "\n",
        "  cout << \"Time of execution: \" << duration.count() / 1000.0f << \"ms\" << endl;\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4iKxc7pDK8P",
        "outputId": "c374bc12-9c6a-4264-87fb-100628d6ddeb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/cpu.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ -std=c++11 -O2 src/cpu.cpp -o cpu"
      ],
      "metadata": {
        "id": "_3Tg93ETDcu8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./cpu 100 10 1 7 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJbZQKZaDjxe",
        "outputId": "88b54a08-5e92-404d-d88b-b78a804142a2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of execution: 0.337ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C++ (GPU) - dev"
      ],
      "metadata": {
        "id": "1PJ6h7_Dmpxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/gpu.cu\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <map>\n",
        "#include <fstream>\n",
        "#include <string>\n",
        "#include <chrono>\n",
        "\n",
        "using namespace std;\n",
        "using namespace std::chrono;\n",
        "\n",
        "enum SearchType{\n",
        "  Indicies,\n",
        "  Entries\n",
        "};\n",
        "\n",
        "enum Device{\n",
        "  CPU,\n",
        "  GPU\n",
        "};\n",
        "\n",
        "ostream& operator<<(ostream& os, const vector<pair<int, int>>& pairs){\n",
        "    os << \"{\";\n",
        "    for (int i = 0; i < pairs.size(); ++i){\n",
        "      auto it = pairs[i];\n",
        "      os << \"(\" << it.first << \", \" << it.second;\n",
        "      os << (i == pairs.size() - 1 ? \")}\" : \"), \");\n",
        "    }\n",
        "\n",
        "    return os;\n",
        "}\n",
        "\n",
        "ostream& operator<<(ostream& os, const vector<bool>& flags){\n",
        "    os << \"{\";\n",
        "    for (int i = 0; i < flags.size(); ++i){\n",
        "      os << (flags[i] ? \"True\" : \"False\");\n",
        "      os << (i == flags.size() - 1 ? \"}\" : \", \");\n",
        "    }\n",
        "\n",
        "    return os;\n",
        "}\n",
        "\n",
        "template<typename T>\n",
        "void printText(const vector<T>& text, ostream& os){ \n",
        "   for (int i = 0; i < text.size(); ++i)\n",
        "   {\n",
        "     os << (T)text[i] << (i == text.size() - 1 ? \"\" : \" \");\n",
        "   }\n",
        "   os << endl;\n",
        "}\n",
        "\n",
        "template<typename T>\n",
        "void printSubs(const vector<vector<T>>& subs, ostream& os){ \n",
        "   for(auto sub : subs){\n",
        "     printText(sub, os);\n",
        "   }\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "vector<int> getSubSizes(const vector<vector<T>>& subs){\n",
        "  vector<int> subsSizes(subs.size(), 0);\n",
        "  for (int subInd = 0; subInd < subs.size(); ++subInd){\n",
        "    subsSizes[subInd] = subs[subInd].size();\n",
        "  }\n",
        "  return subsSizes;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "map<T, vector<pair<int, int>>> generateDict(const vector<T>& alphabet, const vector<vector<T>>& subs){\n",
        "  map<T, vector<pair<int, int>>> dict;\n",
        "  for (auto chr : alphabet){\n",
        "    dict[chr] = vector<pair<int, int>>();\n",
        "  }\n",
        "  \n",
        "  for (int sub_ind = 0; sub_ind < subs.size(); ++sub_ind){\n",
        "    auto sub = subs[sub_ind];\n",
        "    for (int chr_ind = 0; chr_ind < sub.size(); ++chr_ind){\n",
        "      auto chr = sub[chr_ind];\n",
        "      dict[chr].push_back({sub_ind, chr_ind});\n",
        "    }\n",
        "  }\n",
        "  \n",
        "  return dict;\n",
        "}\n",
        "\n",
        "vector<vector<int>> generateMatrix(const vector<int>& subsSizes, int textSize){\n",
        "  vector<vector<int>> mat;\n",
        "  for (auto subSize : subsSizes){\n",
        "    mat.push_back(vector<int>(textSize, subSize));\n",
        "  }\n",
        "  return mat;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "vector<T> generateText(const vector<T>& alphabet, int size){\n",
        "  vector<T> text(size);\n",
        "  for (int i = 0; i < size; ++i){\n",
        "      int ind = rand() % alphabet.size();\n",
        "      text[i] = alphabet[ind];\n",
        "  }\n",
        "  return text;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "vector<vector<T>> generateSubs(const vector<T>& alphabet, int n, int sizeMin, int sizeMax){\n",
        "  vector<vector<T>> subs;\n",
        "\n",
        "  for (int subInd = 0; subInd < n; ++subInd){\n",
        "    int size = sizeMin + rand() % (sizeMax - sizeMin + 1); \n",
        "    auto sub = generateText(alphabet, size);\n",
        "    subs.push_back(sub);\n",
        "  }\n",
        "\n",
        "  return subs;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "void iterateCPU(const vector<T>& text, const map<T, vector<pair<int, int>>>& dict,\n",
        "            vector<vector<int>>& matrix){\n",
        "  for (int chr_ind = 0; chr_ind < text.size(); ++chr_ind){\n",
        "    for (const auto pair : dict.at(text[chr_ind])){\n",
        "      matrix[pair.first][chr_ind - pair.second]--;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  for (int s = 0; s < matrix.size(); ++s){\n",
        "      for (int h = 0; h <  matrix[0].size(); ++h){\n",
        "        printf(\"%d \", matrix[s][h]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "void checkError(cudaError_t error){\n",
        "\tif (error != cudaSuccess){\n",
        "\t\tcout << \"Error\" << endl;\n",
        "\t\tcerr << cudaGetErrorString(error) << endl;\n",
        "\t\texit(1);\n",
        "\t}\n",
        "}\n",
        "\n",
        "// H - length of a text\n",
        "// N - number of substrings\n",
        "// C - Alphabet size\n",
        "template<int blockSize>\n",
        "__global__ void kernel(int* text, int H, int* matrix, int N, int* dict, int C) {\n",
        "  int tid = threadIdx.x;\n",
        "  int i = blockIdx.x * blockSize + tid;\n",
        "\n",
        "  if (i >= H) return;\n",
        "\n",
        "  __shared__ int sdata[blockSize];\n",
        "\n",
        "  int chr = text[i];\n",
        "\n",
        "  int offset = 3 * chr;\n",
        "  int pos = dict[offset + 1];\n",
        "  int n = dict[offset + 2];\n",
        "\n",
        "  if (i == 0){\n",
        "    for (int s = 0; s < N; ++s){\n",
        "      for (int h = 0; h < H; ++h){\n",
        "        printf(\"%d \", matrix[s * H + h]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "    }\n",
        "  }\n",
        "\n",
        "  if (i == 0){\n",
        "    printf(\"i\\tchr\\toffset\\tpos\\tn\\n\");\n",
        "  }\n",
        "  \n",
        "  __syncthreads();\n",
        "  printf(\"%d\\t%d\\t%d\\t%d\\t%d\\n\", i, chr, offset, pos, n);\n",
        "\n",
        "  for (int pair_ind = 0; pair_ind < n; ++pair_ind){\n",
        "    int ind = pos + pair_ind * 2;\n",
        "    \n",
        "    printf(\"i=%d chr=%d ind=%d sub_ind=%d chr_ind=%d\\n\", i, chr, ind, dict[ind], dict[ind+1]);\n",
        "    atomicSub(matrix + dict[ind] * H + i - dict[ind + 1], 1);\n",
        "    printf(\"%d\\n\", dict[ind] * H + i - dict[ind + 1]);\n",
        "  }\n",
        "\n",
        "  if (i == 0){\n",
        "    for (int s = 0; s < N; ++s){\n",
        "      for (int h = 0; h < H; ++h){\n",
        "        printf(\"%d \", matrix[s * H + h]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "    }\n",
        "  } \n",
        "}\n",
        "\n",
        "// working if char type is int and alphabet is 0..N\n",
        "void iterateGPU(const vector<int>& text, const map<int, vector<pair<int, int>>>& dict,\n",
        "            vector<vector<int>>& matrix){\n",
        "  \n",
        "  int textSize = text.size();\n",
        "  int N = matrix.size();\n",
        "  int H = matrix[0].size();\n",
        "  int alphabetSize = dict.size();\n",
        "  int entryNumber = 0;\n",
        "\n",
        "  // Flatten map into [(char, offset, n)][(sub_ind, pos_ind)]\n",
        "  vector<int> dictHost;\n",
        "  for (auto const& it : dict){\n",
        "    \n",
        "    dictHost.push_back(it.first);\n",
        "    dictHost.push_back(3 * alphabetSize + entryNumber * 2);\n",
        "    dictHost.push_back(it.second.size());\n",
        "\n",
        "    entryNumber += it.second.size();\n",
        "  }\n",
        "\n",
        "  cout << 2 << endl;\n",
        "\n",
        "  int dictDeviceSize = 3 * alphabetSize + 2 * entryNumber;\n",
        "\n",
        "  // Device pointers\n",
        "  int* textDevice;\n",
        "  int* matrixDevice;\n",
        "  int* dictDevice; // [(char, offset, n)][(sub_ind, pos_ind)]\n",
        "  // Temporary memory for flat pairs\n",
        "  int* flatPairs = new int[2 * entryNumber];\n",
        "\n",
        "  // Copy text to a device\n",
        "  checkError(cudaMalloc(&textDevice, textSize * sizeof(int)));\n",
        "  checkError(cudaMemcpy(textDevice, &text[0], textSize * sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  cout << 3 << endl;\n",
        "\n",
        "  // Flatten and copy matrix to a device\n",
        "  checkError(cudaMalloc(&matrixDevice, N * H * sizeof(int)));\n",
        "  for (int sub_ind = 0; sub_ind < N; ++sub_ind){\n",
        "    checkError(cudaMemcpy(matrixDevice + sub_ind * H, &matrix[sub_ind][0], textSize * sizeof(int), cudaMemcpyHostToDevice));\n",
        "  }\n",
        "\n",
        "  cout << 4 << endl;\n",
        "\n",
        "  // Copy meta part of map to a device [(char, offset, n)]\n",
        "  checkError(cudaMalloc(&dictDevice, dictDeviceSize * sizeof(int)));\n",
        "  checkError(cudaMemcpy(dictDevice, &dictHost[0], 3 * alphabetSize * sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  cout << 5 << endl;\n",
        "  \n",
        "  // Flatten and copy map data to a device [(sub_ind, pos_ind)]\n",
        "  int curPos = 0;\n",
        "  for (auto pairs : dict){\n",
        "    for (auto pair : pairs.second){\n",
        "      flatPairs[curPos++] = pair.first;\n",
        "      flatPairs[curPos++] = pair.second;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  checkError(cudaMemcpy(dictDevice + 3 * alphabetSize, flatPairs, 2 * entryNumber * sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  cout << 6 << endl;\n",
        "\n",
        "  const int blockX = 128;\n",
        "  const int gridX = int(1.0f * (textSize - 1) / blockX) + 1;\n",
        "\n",
        "  cout << 7 << endl;\n",
        "\n",
        "  kernel<blockX><<<gridX, blockX>>>(textDevice, textSize, matrixDevice, N, dictDevice, alphabetSize);\n",
        "  checkError(cudaDeviceSynchronize());\n",
        "\n",
        "  cout << 8 << endl;\n",
        "\n",
        "  for (int i = 0; i < N; ++i){\n",
        "    checkError(cudaMemcpy(&matrix[i][0], (matrixDevice + i * H), H * sizeof(int), cudaMemcpyDeviceToHost));\n",
        "  }\n",
        "\n",
        "  cout << 9 << endl;\n",
        "\n",
        "\n",
        "  delete[] flatPairs;\n",
        "  cudaFree(matrixDevice);\n",
        "  cudaFree(textDevice);\n",
        "  cudaFree(dictDevice);\n",
        "\n",
        "}\n",
        "\n",
        "vector<pair<int, int>> findIndices(const vector<vector<int>>& mat){\n",
        "  vector<pair<int, int>> result;\n",
        "\n",
        "  int textSize = mat[0].size();\n",
        "\n",
        "  for (int subInd = 0; subInd < mat.size(); ++subInd){\n",
        "    for (int textPos = 0; textPos < textSize; ++textPos){\n",
        "      if (mat[subInd][textPos] == 0){\n",
        "        result.push_back({subInd, textPos});\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  return result;\n",
        "}\n",
        "\n",
        "vector<bool> findEntries(const vector<vector<int>>& mat){\n",
        "  \n",
        "  vector<bool> result(mat.size(), false);\n",
        "  int textSize = mat[0].size();\n",
        "\n",
        "  for (int subInd = 0; subInd < mat.size(); ++subInd){\n",
        "    for (int textPos = 0; textPos < textSize; ++textPos){\n",
        "      if (mat[subInd][textPos] == 0){\n",
        "        result[subInd] = true;\n",
        "        break;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  return result;\n",
        "}\n",
        "\n",
        "float search(int textSize, int subN, int subSizeMin, \n",
        "            int subSizeMax, SearchType searchType, Device device){\n",
        "  \n",
        "  ofstream myfile;\n",
        "  myfile.open (\"data.txt\");\n",
        "\n",
        "  float totalTime = 0.0f;\n",
        "  \n",
        "\n",
        "  // Generate 8bit alphabet\n",
        "  /*\n",
        "  int alphabetSize = 256;\n",
        "  vector<int> alphabet(alphabetSize);\n",
        "  for (int i = 0; i < alphabetSize; ++i){\n",
        "    alphabet[i] = i;\n",
        "  }\n",
        "\n",
        "  // Generate text\n",
        "  vector<int> text = generateText<int>(alphabet, textSize);\n",
        "  \n",
        "  // Generate substrings\n",
        "  auto subs = generateSubs<int>(alphabet, subN, subSizeMin, subSizeMax);\n",
        "  vector<int> subsSizes = getSubSizes<int>(subs);\n",
        "  */\n",
        "\n",
        "  int alphabetSize = 7;\n",
        "  textSize = 11;\n",
        "  vector<int> alphabet = {0, 1, 2, 3, 4, 5, 6};\n",
        "  vector<int> text = {0, 1, 2, 0, 1, 2, 4, 5, 6, 6, 0};\n",
        "  vector<vector<int>> subs = {{0, 1, 2}, {2, 4}, {6}};\n",
        "  vector<int> subsSizes = getSubSizes<int>(subs);\n",
        "  \n",
        "  // Preliminary step\n",
        "  map<int, vector<pair<int, int>>> dict = generateDict<int>(alphabet, subs);\n",
        "  vector<vector<int>> mat = generateMatrix(subsSizes, textSize);\n",
        "  \n",
        "  // Algorithm steps\n",
        "  if (device == CPU){\n",
        "    auto start = high_resolution_clock::now();\n",
        "    iterateCPU<int>(text, dict, mat);\n",
        "    auto end = high_resolution_clock::now();\n",
        "    auto duration = duration_cast<microseconds>(end - start);\n",
        "    totalTime = duration.count() / 1000.0f;\n",
        "  }\n",
        "  else{\n",
        "    cudaEvent_t startEvent, stopEvent;\n",
        "    checkError(cudaEventCreate(&startEvent));\n",
        "    checkError(cudaEventCreate(&stopEvent));\n",
        "    \n",
        "\n",
        "    checkError(cudaEventRecord(startEvent, 0));\n",
        "    iterateGPU(text, dict, mat);\n",
        "    checkError(cudaEventRecord(stopEvent, 0));\n",
        "\n",
        "    checkError(cudaDeviceSynchronize());\n",
        "    checkError(cudaEventElapsedTime(&totalTime, startEvent, stopEvent));\n",
        "\n",
        "  }\n",
        "\n",
        "  // Save input data\n",
        "  myfile << textSize << \" \" << subN << \" \" <<  subSizeMin << \" \"\n",
        "     << subSizeMax << \" \" << searchType << endl;\n",
        "  printText(alphabet, myfile);\n",
        "  printText(text, myfile);\n",
        "  printSubs(subs, myfile);\n",
        "\n",
        "  // Interpret results\n",
        "  switch(searchType){\n",
        "    case Indicies:{\n",
        "      vector<pair<int, int>> indices = findIndices(mat);\n",
        "      myfile << indices << endl;\n",
        "    }\n",
        "    break;\n",
        "    case Entries:{\n",
        "      vector<bool> entries = findEntries(mat);\n",
        "      myfile << entries << endl;\n",
        "      break;\n",
        "    } \n",
        "  }\n",
        "  myfile.close();\n",
        "\n",
        "  return totalTime;\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "  srand(42);\n",
        "\n",
        "  int textSize = stoi(argv[1]);\n",
        "  int subN = stoi(argv[2]);\n",
        "  int subSizeMin = stoi(argv[3]);\n",
        "  int subSizeMax = stoi(argv[4]);\n",
        "  SearchType searchType = (SearchType)stoi(argv[5]);\n",
        "  Device device = (Device)stoi(argv[6]);\n",
        "\n",
        "  \n",
        "  cout << 1 << endl;\n",
        "  float duration = search(textSize, subN, subSizeMin, subSizeMax, searchType, device);\n",
        "  cout << \"Time of execution: \" << duration << \"ms\" << endl;\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "Ucg5Z5i5mxMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e6c67b-a53c-4c3f-f41b-f29c70f4a2c1"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc src/gpu.cu -o gpu"
      ],
      "metadata": {
        "id": "IodAyXoIp26j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "478bd218-c223-49fb-e880-8470c5ac8a73"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src/gpu.cu(343): warning: variable \"alphabetSize\" was declared but never referenced\n",
            "\n",
            "src/gpu.cu(153): warning: variable \"sdata\" was declared but never referenced\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# textSize subN subSizeMin subSizeMax searchType(0 - inds, 1 - entry) device (0 - CPU, 1 - GPU)\n",
        "!./gpu 1000 10 1 7 0 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPNvGLJaIP7V",
        "outputId": "be0f84c2-2922-407b-c68f-24ded64a3199"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "6\n",
            "7\n",
            "3 3 3 3 3 3 3 3 3 3 3 \n",
            "2 2 2 2 2 2 2 2 2 2 2 \n",
            "1 1 1 1 1 1 1 1 1 1 1 \n",
            "i\tchr\toffset\tpos\tn\n",
            "0\t0\t0\t21\t1\n",
            "1\t1\t3\t23\t1\n",
            "2\t2\t6\t25\t2\n",
            "3\t0\t0\t21\t1\n",
            "4\t1\t3\t23\t1\n",
            "5\t2\t6\t25\t2\n",
            "6\t4\t12\t29\t1\n",
            "7\t5\t15\t31\t0\n",
            "8\t6\t18\t31\t1\n",
            "9\t6\t18\t31\t1\n",
            "10\t0\t0\t21\t1\n",
            "i=0 chr=0 ind=21 sub_ind=0 chr_ind=0\n",
            "i=1 chr=1 ind=23 sub_ind=0 chr_ind=1\n",
            "i=2 chr=2 ind=25 sub_ind=0 chr_ind=2\n",
            "i=3 chr=0 ind=21 sub_ind=0 chr_ind=0\n",
            "i=4 chr=1 ind=23 sub_ind=0 chr_ind=1\n",
            "i=5 chr=2 ind=25 sub_ind=0 chr_ind=2\n",
            "i=6 chr=4 ind=29 sub_ind=1 chr_ind=1\n",
            "i=8 chr=6 ind=31 sub_ind=2 chr_ind=0\n",
            "i=9 chr=6 ind=31 sub_ind=2 chr_ind=0\n",
            "i=10 chr=0 ind=21 sub_ind=0 chr_ind=0\n",
            "0\n",
            "0\n",
            "0\n",
            "3\n",
            "3\n",
            "3\n",
            "16\n",
            "30\n",
            "31\n",
            "10\n",
            "i=2 chr=2 ind=27 sub_ind=1 chr_ind=0\n",
            "i=5 chr=2 ind=27 sub_ind=1 chr_ind=0\n",
            "13\n",
            "16\n",
            "0 3 3 0 3 3 3 3 3 3 2 \n",
            "2 2 1 2 2 0 2 2 2 2 2 \n",
            "1 1 1 1 1 1 1 1 0 0 1 \n",
            "8\n",
            "9\n",
            "Time of execution: 5.01981ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./gpu 1000 10 1 7 0 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDuUFA-B2qO_",
        "outputId": "6050eab6-a1b9-4b1c-c3e8-049e12eee066"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0 3 3 0 3 3 3 3 3 3 2 \n",
            "2 2 1 2 2 0 2 2 2 2 2 \n",
            "1 1 1 1 1 1 1 1 0 0 1 \n",
            "Time of execution: 0.03ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C++ (CUDA) - prod"
      ],
      "metadata": {
        "id": "UGHTg-QpnK5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/gpu.cu\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <map>\n",
        "#include <fstream>\n",
        "#include <string>\n",
        "#include <chrono>\n",
        "\n",
        "using namespace std;\n",
        "using namespace std::chrono;\n",
        "\n",
        "enum SearchType{\n",
        "  Indicies,\n",
        "  Entries\n",
        "};\n",
        "\n",
        "enum Device{\n",
        "  CPU,\n",
        "  GPU\n",
        "};\n",
        "\n",
        "ostream& operator<<(ostream& os, const vector<pair<int, int>>& pairs){\n",
        "    os << \"{\";\n",
        "    for (int i = 0; i < pairs.size(); ++i){\n",
        "      auto it = pairs[i];\n",
        "      os << \"(\" << it.first << \", \" << it.second;\n",
        "      os << (i == pairs.size() - 1 ? \")}\" : \"), \");\n",
        "    }\n",
        "\n",
        "    return os;\n",
        "}\n",
        "\n",
        "ostream& operator<<(ostream& os, const vector<bool>& flags){\n",
        "    os << \"{\";\n",
        "    for (int i = 0; i < flags.size(); ++i){\n",
        "      os << (flags[i] ? \"True\" : \"False\");\n",
        "      os << (i == flags.size() - 1 ? \"}\" : \", \");\n",
        "    }\n",
        "\n",
        "    return os;\n",
        "}\n",
        "\n",
        "template<typename T>\n",
        "void printText(const vector<T>& text, ostream& os){ \n",
        "   for (int i = 0; i < text.size(); ++i)\n",
        "   {\n",
        "     os << (T)text[i] << (i == text.size() - 1 ? \"\" : \" \");\n",
        "   }\n",
        "   os << endl;\n",
        "}\n",
        "\n",
        "template<typename T>\n",
        "void printSubs(const vector<vector<T>>& subs, ostream& os){ \n",
        "   for(auto sub : subs){\n",
        "     printText(sub, os);\n",
        "   }\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "vector<int> getSubSizes(const vector<vector<T>>& subs){\n",
        "  vector<int> subsSizes(subs.size(), 0);\n",
        "  for (int subInd = 0; subInd < subs.size(); ++subInd){\n",
        "    subsSizes[subInd] = subs[subInd].size();\n",
        "  }\n",
        "  return subsSizes;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "map<T, vector<pair<int, int>>> generateDict(const vector<T>& alphabet, const vector<vector<T>>& subs){\n",
        "  map<T, vector<pair<int, int>>> dict;\n",
        "  for (auto chr : alphabet){\n",
        "    dict[chr] = vector<pair<int, int>>();\n",
        "  }\n",
        "  \n",
        "  for (int sub_ind = 0; sub_ind < subs.size(); ++sub_ind){\n",
        "    auto sub = subs[sub_ind];\n",
        "    for (int chr_ind = 0; chr_ind < sub.size(); ++chr_ind){\n",
        "      auto chr = sub[chr_ind];\n",
        "      dict[chr].push_back({sub_ind, chr_ind});\n",
        "    }\n",
        "  }\n",
        "  \n",
        "  return dict;\n",
        "}\n",
        "\n",
        "vector<vector<int>> generateMatrix(const vector<int>& subsSizes, int textSize){\n",
        "  vector<vector<int>> mat;\n",
        "  for (auto subSize : subsSizes){\n",
        "    mat.push_back(vector<int>(textSize, subSize));\n",
        "  }\n",
        "  return mat;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "vector<T> generateText(const vector<T>& alphabet, int size){\n",
        "  vector<T> text(size);\n",
        "  for (int i = 0; i < size; ++i){\n",
        "      int ind = rand() % alphabet.size();\n",
        "      text[i] = alphabet[ind];\n",
        "  }\n",
        "  return text;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "vector<vector<T>> generateSubs(const vector<T>& alphabet, int n, int sizeMin, int sizeMax){\n",
        "  vector<vector<T>> subs;\n",
        "\n",
        "  for (int subInd = 0; subInd < n; ++subInd){\n",
        "    int size = sizeMin + rand() % (sizeMax - sizeMin + 1); \n",
        "    auto sub = generateText(alphabet, size);\n",
        "    subs.push_back(sub);\n",
        "  }\n",
        "\n",
        "  return subs;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "void iterateCPU(const vector<T>& text, const map<T, vector<pair<int, int>>>& dict,\n",
        "            vector<vector<int>>& matrix){\n",
        "  for (int chr_ind = 0; chr_ind < text.size(); ++chr_ind){\n",
        "    for (const auto pair : dict.at(text[chr_ind])){\n",
        "      matrix[pair.first][chr_ind - pair.second]--;\n",
        "    }\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "void checkError(cudaError_t error){\n",
        "\tif (error != cudaSuccess){\n",
        "\t\tcout << \"Error\" << endl;\n",
        "\t\tcerr << cudaGetErrorString(error) << endl;\n",
        "\t\texit(1);\n",
        "\t}\n",
        "}\n",
        "\n",
        "// H - length of a text\n",
        "// N - number of substrings\n",
        "// C - Alphabet size\n",
        "template<int blockSize>\n",
        "__global__ void kernel(int* text, int H, int* matrix, int N, int* dict, int C) {\n",
        "  int tid = threadIdx.x;\n",
        "  int i = blockIdx.x * blockSize + tid;\n",
        "\n",
        "  if (i >= H) return;\n",
        "\n",
        "  int chr = text[i];\n",
        "\n",
        "  int offset = 3 * chr;\n",
        "  int pos = dict[offset + 1];\n",
        "  int n = dict[offset + 2];\n",
        "\n",
        "  for (int pair_ind = 0; pair_ind < n; ++pair_ind){\n",
        "    int ind = pos + pair_ind * 2;\n",
        "    atomicSub(matrix + dict[ind] * H + i - dict[ind + 1], 1);\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "// working if char type is int and alphabet is 0..N\n",
        "void iterateGPU(const vector<int>& text, const map<int, vector<pair<int, int>>>& dict,\n",
        "            vector<vector<int>>& matrix){\n",
        "  int textSize = text.size();\n",
        "  int N = matrix.size();\n",
        "  int H = matrix[0].size();\n",
        "  int alphabetSize = dict.size();\n",
        "  int entryNumber = 0;\n",
        "\n",
        "  // Flatten map into [(char, offset, n)][(sub_ind, pos_ind)]\n",
        "  vector<int> dictHost;\n",
        "  for (auto const& it : dict){\n",
        "    \n",
        "    dictHost.push_back(it.first);\n",
        "    dictHost.push_back(3 * alphabetSize + entryNumber * 2);\n",
        "    dictHost.push_back(it.second.size());\n",
        "\n",
        "    entryNumber += it.second.size();\n",
        "  }\n",
        "\n",
        "  int dictDeviceSize = 3 * alphabetSize + 2 * entryNumber;\n",
        "\n",
        "  // Device pointers\n",
        "  int* textDevice;\n",
        "  int* matrixDevice;\n",
        "  int* dictDevice; // [(char, offset, n)][(sub_ind, pos_ind)]\n",
        "  // Temporary memory for flat pairs\n",
        "  int* flatPairs = new int[2 * entryNumber];\n",
        "\n",
        "  // Copy text to a device\n",
        "  checkError(cudaMalloc(&textDevice, textSize * sizeof(int)));\n",
        "  checkError(cudaMemcpy(textDevice, &text[0], textSize * sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  // Flatten and copy matrix to a device\n",
        "  checkError(cudaMalloc(&matrixDevice, N * H * sizeof(int)));\n",
        "  for (int sub_ind = 0; sub_ind < N; ++sub_ind){\n",
        "    checkError(cudaMemcpy(matrixDevice + sub_ind * H, &matrix[sub_ind][0], textSize * sizeof(int), cudaMemcpyHostToDevice));\n",
        "  }\n",
        "\n",
        "  // Copy meta part of map to a device [(char, offset, n)]\n",
        "  checkError(cudaMalloc(&dictDevice, dictDeviceSize * sizeof(int)));\n",
        "  checkError(cudaMemcpy(dictDevice, &dictHost[0], 3 * alphabetSize * sizeof(int), cudaMemcpyHostToDevice));\n",
        "  \n",
        "  // Flatten and copy map data to a device [(sub_ind, pos_ind)]\n",
        "  int curPos = 0;\n",
        "  for (auto pairs : dict){\n",
        "    for (auto pair : pairs.second){\n",
        "      flatPairs[curPos++] = pair.first;\n",
        "      flatPairs[curPos++] = pair.second;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  checkError(cudaMemcpy(dictDevice + 3 * alphabetSize, flatPairs, 2 * entryNumber * sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  const int blockX = 128;\n",
        "  const int gridX = int(1.0f * (textSize - 1) / blockX) + 1;\n",
        "\n",
        "  kernel<blockX><<<gridX, blockX>>>(textDevice, textSize, matrixDevice, N, dictDevice, alphabetSize);\n",
        "  checkError(cudaDeviceSynchronize());\n",
        "\n",
        "  for (int i = 0; i < N; ++i){\n",
        "    checkError(cudaMemcpy(&matrix[i][0], (matrixDevice + i * H), H * sizeof(int), cudaMemcpyDeviceToHost));\n",
        "  }\n",
        "\n",
        "  delete[] flatPairs;\n",
        "  cudaFree(matrixDevice);\n",
        "  cudaFree(textDevice);\n",
        "  cudaFree(dictDevice);\n",
        "}\n",
        "\n",
        "vector<pair<int, int>> findIndices(const vector<vector<int>>& mat){\n",
        "  vector<pair<int, int>> result;\n",
        "\n",
        "  int textSize = mat[0].size();\n",
        "\n",
        "  for (int subInd = 0; subInd < mat.size(); ++subInd){\n",
        "    for (int textPos = 0; textPos < textSize; ++textPos){\n",
        "      if (mat[subInd][textPos] == 0){\n",
        "        result.push_back({subInd, textPos});\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  return result;\n",
        "}\n",
        "\n",
        "vector<bool> findEntries(const vector<vector<int>>& mat){\n",
        "  \n",
        "  vector<bool> result(mat.size(), false);\n",
        "  int textSize = mat[0].size();\n",
        "\n",
        "  for (int subInd = 0; subInd < mat.size(); ++subInd){\n",
        "    for (int textPos = 0; textPos < textSize; ++textPos){\n",
        "      if (mat[subInd][textPos] == 0){\n",
        "        result[subInd] = true;\n",
        "        break;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  return result;\n",
        "}\n",
        "\n",
        "bool checkEquality(const vector<vector<int>>& mat1, const vector<vector<int>>& mat2){\n",
        "  for (int i = 0; i < mat1.size(); ++i){\n",
        "    for (int j = 0; j < mat1[0].size(); ++j){\n",
        "      if (mat1[i][j] != mat2[i][j]){\n",
        "        return false;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  return true;\n",
        "}\n",
        "\n",
        "void experiment(int textSize, int subN, int subSizeMin, \n",
        "            int subSizeMax, SearchType searchType){\n",
        "  ofstream myfile;\n",
        "  myfile.open (\"data.txt\");\n",
        "\n",
        "  float totalTime = 0.0f;\n",
        "\n",
        "  // Generate 8bit alphabet\n",
        "\n",
        "  int alphabetSize = 256;\n",
        "  vector<int> alphabet(alphabetSize);\n",
        "  for (int i = 0; i < alphabetSize; ++i){\n",
        "    alphabet[i] = i;\n",
        "  }\n",
        "\n",
        "  // Generate text\n",
        "  vector<int> text = generateText<int>(alphabet, textSize);\n",
        "  \n",
        "  // Generate substrings\n",
        "  auto subs = generateSubs<int>(alphabet, subN, subSizeMin, subSizeMax);\n",
        "  vector<int> subsSizes = getSubSizes<int>(subs);\n",
        "  \n",
        "  // Preliminary step\n",
        "  map<int, vector<pair<int, int>>> dict = generateDict<int>(alphabet, subs);\n",
        "  vector<vector<int>> mat1 = generateMatrix(subsSizes, textSize);\n",
        "  vector<vector<int>> mat2 = generateMatrix(subsSizes, textSize); // copy\n",
        "\n",
        "  // Save input data\n",
        "  myfile << textSize << \" \" << subN << \" \" <<  subSizeMin << \" \"\n",
        "     << subSizeMax << \" \" << searchType << endl;\n",
        "  printText(alphabet, myfile);\n",
        "  printText(text, myfile);\n",
        "  printSubs(subs, myfile);\n",
        "\n",
        "  // CPU\n",
        "  auto start = high_resolution_clock::now();\n",
        "  iterateCPU<int>(text, dict, mat1);\n",
        "  auto end = high_resolution_clock::now();\n",
        "  auto duration = duration_cast<microseconds>(end - start);\n",
        "  totalTime = duration.count() / 1000.0f;\n",
        "\n",
        "  cout << \"CPU time: \" << totalTime << endl;\n",
        "  \n",
        "  // CUDA\n",
        "  cudaEvent_t startEvent, stopEvent;\n",
        "  checkError(cudaEventCreate(&startEvent));\n",
        "  checkError(cudaEventCreate(&stopEvent));\n",
        "  \n",
        "  checkError(cudaEventRecord(startEvent, 0));\n",
        "  iterateGPU(text, dict, mat2);\n",
        "  checkError(cudaEventRecord(stopEvent, 0));\n",
        "\n",
        "  checkError(cudaDeviceSynchronize());\n",
        "  checkError(cudaEventElapsedTime(&totalTime, startEvent, stopEvent));\n",
        "\n",
        "  cout << \"GPU time: \" << totalTime << endl;\n",
        "\n",
        "  // Check equality\n",
        "  if (checkEquality(mat1, mat2)){\n",
        "    cout << \"Correct!\" << endl;\n",
        "  }\n",
        "  else{\n",
        "    cout << \"Incorect!\" << endl;\n",
        "  }\n",
        "\n",
        "  // Interpret results\n",
        "  switch(searchType){\n",
        "    case Indicies:{\n",
        "      vector<pair<int, int>> indices = findIndices(mat1);\n",
        "      myfile << indices << endl;\n",
        "    }\n",
        "    break;\n",
        "    case Entries:{\n",
        "      vector<bool> entries = findEntries(mat1);\n",
        "      myfile << entries << endl;\n",
        "      break;\n",
        "    } \n",
        "  }\n",
        "  myfile.close();\n",
        "}\n",
        "\n",
        "float search(int textSize, int subN, int subSizeMin, \n",
        "            int subSizeMax, SearchType searchType, Device device){\n",
        "  \n",
        "  ofstream myfile;\n",
        "  myfile.open (\"data.txt\");\n",
        "\n",
        "  float totalTime = 0.0f;\n",
        "  \n",
        "  // Generate 8bit alphabet\n",
        "\n",
        "  int alphabetSize = 256;\n",
        "  vector<int> alphabet(alphabetSize);\n",
        "  for (int i = 0; i < alphabetSize; ++i){\n",
        "    alphabet[i] = i;\n",
        "  }\n",
        "\n",
        "  // Generate text\n",
        "  vector<int> text = generateText<int>(alphabet, textSize);\n",
        "  \n",
        "  // Generate substrings\n",
        "  auto subs = generateSubs<int>(alphabet, subN, subSizeMin, subSizeMax);\n",
        "  vector<int> subsSizes = getSubSizes<int>(subs);\n",
        "  \n",
        "  // Preliminary step\n",
        "  map<int, vector<pair<int, int>>> dict = generateDict<int>(alphabet, subs);\n",
        "  vector<vector<int>> mat = generateMatrix(subsSizes, textSize);\n",
        "  \n",
        "  // Algorithm steps\n",
        "  if (device == CPU){\n",
        "    auto start = high_resolution_clock::now();\n",
        "    iterateCPU<int>(text, dict, mat);\n",
        "    auto end = high_resolution_clock::now();\n",
        "    auto duration = duration_cast<microseconds>(end - start);\n",
        "    totalTime = duration.count() / 1000.0f;\n",
        "  }\n",
        "  else if (device == GPU){\n",
        "    cudaEvent_t startEvent, stopEvent;\n",
        "    checkError(cudaEventCreate(&startEvent));\n",
        "    checkError(cudaEventCreate(&stopEvent));\n",
        "    \n",
        "    checkError(cudaEventRecord(startEvent, 0));\n",
        "    iterateGPU(text, dict, mat);\n",
        "    checkError(cudaEventRecord(stopEvent, 0));\n",
        "\n",
        "    checkError(cudaDeviceSynchronize());\n",
        "    checkError(cudaEventElapsedTime(&totalTime, startEvent, stopEvent));\n",
        "  }\n",
        "\n",
        "  // Save input data\n",
        "  myfile << textSize << \" \" << subN << \" \" <<  subSizeMin << \" \"\n",
        "     << subSizeMax << \" \" << searchType << endl;\n",
        "  printText(alphabet, myfile);\n",
        "  printText(text, myfile);\n",
        "  printSubs(subs, myfile);\n",
        "\n",
        "  // Interpret results\n",
        "  switch(searchType){\n",
        "    case Indicies:{\n",
        "      vector<pair<int, int>> indices = findIndices(mat);\n",
        "      myfile << indices << endl;\n",
        "    }\n",
        "    break;\n",
        "    case Entries:{\n",
        "      vector<bool> entries = findEntries(mat);\n",
        "      myfile << entries << endl;\n",
        "      break;\n",
        "    } \n",
        "  }\n",
        "  myfile.close();\n",
        "\n",
        "  return totalTime;\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "  srand(42);\n",
        "\n",
        "  int textSize = stoi(argv[1]);\n",
        "  int subN = stoi(argv[2]);\n",
        "  int subSizeMin = stoi(argv[3]);\n",
        "  int subSizeMax = stoi(argv[4]);\n",
        "  SearchType searchType = (SearchType)stoi(argv[5]);\n",
        "  //Device device = (Device)stoi(argv[6]);\n",
        "  //float duration = search(textSize, subN, subSizeMin, subSizeMax, searchType, device);\n",
        "  //cout << \"Time of execution: \" << duration << \"ms\" << endl;\n",
        "\n",
        "  experiment(textSize, subN, subSizeMin, subSizeMax, searchType);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRlaDv9i3kQ_",
        "outputId": "600714c5-1b52-460a-b61d-9a6af3490fe2"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc src/gpu.cu -o gpu"
      ],
      "metadata": {
        "id": "5bKZn9LA3zla"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# textSize subN subSizeMin subSizeMax searchType(0 - inds, 1 - entry) device (0 - CPU, 1 - GPU)\n",
        "!./gpu 1000000 20 1 20 0 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZi2RTuN35--",
        "outputId": "3ba9cd3e-fd2e-4dcf-b94b-29ce246d6af0"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU time: 390.294\n",
            "GPU time: 45.3081\n",
            "Incorect!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sqWV0F1Q37Nc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}