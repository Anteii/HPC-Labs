# Отчет по первой лабораторной работе (Matrix multiplication)

## Содержание отчета

* [Описание работы](#описание-работы)
* [Описание реализации](#описание-реализации)
* [Результаты](#результаты)

## Описание работы
Данная лабораторная работа выполнена в среде google colab, поскольку она предоставлет доступ к виртуальной линукс машине с видеоадаптером nvidia (cuda-compatible, в моем случае это была nvidia tesla T4) и дает возможность компилировать и исполнять C++/Cuda программы. Каждая ячейка помеченная %%cu интерпретируется средой как C++/Cuda код и соответственно компилируется с помощью nvcc. Вывод программы перенаправляется в вывод ячейки.

Ноутбук состоит из 4 разделов:

- Setup (установка необходимого расширения и проверка устройства nvidia)
- Test program ("Hello World" )
- Matrix Multiplcation (ячейка с непосредственно кодом лабораторной работы)
- Visualization (построение графиков и других визуализаций полученных результатов)

## Описание реализации

Вся реализация содержится в разделе Matrix Multiplication в ноутбуке.

Особенности реализации:

- Матрицы хранятся как одномерный массив (по строкам)
- Каждый эксперимент выполнялся несколько раз с последующим усреднением времени


Были объявлены и определены вспомогательные функции: 

- randomFillCPU (заполняет матрицу случайными числами)
- checkError (по коду, возвращаемому cuda-функцией опредляет была ли ошибка)
- checkEquality (проверка на равенство двух матриц)
- printMatrix (вывод матрицы в консоль)
- experiment (инкапсулирует логику эксперимента: повторяет умножение несколько раз для входных параметров, каждый раз заполняя матрицы новыми значениями, усредняет время выполнения)

Функции матричного умножения:

- cpuMatMul (классический алгоритм умножения матриц)
- gpuMatMul (содержит выделение/освобождение памяти видеокарты, пересылку данных, вызов ядра, замер времени)
- matMulKernel (ядро)

Алгоритм реализации матричного умножения на GPU представлен в виде функции-ядра matMulKernel. Логика работы такая, что каждый элемент результирующей матрицы вычисляется разными нитями:
    
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

Здесь (row, col) - индекс элемента результирующей матрицы. За счет того, что нити работаю паралелльно, достигается ускорение по сравнению с реализацией матричного умножения (последовательная версия) на CPU.

Эксперименты - воспроизводимы (random seed fixed).

## Результаты
В ходе работы были проведены замеры времени выполнения матричного умножения на CPU и GPU для квадратных матриц.

<p align="center">
  <img width="600" height="300" src="https://github.com/Anteii/HPC-Labs/blob/main/lab1/resources/время.png"/>
</p>

А также ускорение.

<p align="center">
  <img width="600" height="300" src="https://github.com/Anteii/HPC-Labs/blob/main/lab1/resources/ускорение.png">
</p>

Также были проведены эксперименты для прямоугольных матриц.

<p align="center">
  <img width="420" height="280" src="https://github.com/Anteii/HPC-Labs/blob/main/lab1/resources/cpu_time_3d.png">
  <img width="420" height="280" src="https://github.com/Anteii/HPC-Labs/blob/main/lab1/resources/gpu_time_3d.png">
  <img width="420" height="280" src="https://github.com/Anteii/HPC-Labs/blob/main/lab1/resources/speed_up_ed.png">
</p>
